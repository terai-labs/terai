---
title: AI Translator
description: Learn how to use AI-powered translation with Terai using the Vercel AI SDK for high-quality, context-aware translations.
---

**Terai** provides a powerful AI-based translator that leverages the [Vercel AI SDK](https://sdk.vercel.ai/) to deliver high-quality, context-aware translations for your application. This translator supports any AI model provider, giving you complete flexibility in choosing the best model for your needs.

## Overview

The `createAiTranslator` function creates an intelligent translator that:

- **Preserves Code Patterns**: Maintains template variables (`${var}`, `{count}`, etc.), HTML tags, and special characters
- **Context-Aware**: Understands UI elements, error messages, and technical terminology
- **Flexible Model Support**: Works with any AI SDK provider (OpenAI, Anthropic, Groq, Google, etc.)
- **Structured Output**: Uses Zod schema validation to ensure consistent translation format
- **Professional Quality**: Includes a comprehensive system prompt optimized for software localization

## Installation

<Steps>

### Install Dependencies

Install the required packages for AI translation:

<Tabs items={['npm', 'pnpm', 'yarn', 'bun']}>
  <Tabs.Tab>
  ```bash copy
  npm install @terai/dev ai zod
  # Install your preferred AI SDK provider
  npm install @ai-sdk/openai  # For OpenAI
  # OR
  npm install @ai-sdk/anthropic  # For Anthropic
  # OR
  npm install @ai-sdk/groq  # For Groq
  ```
  </Tabs.Tab>
  <Tabs.Tab>
  ```bash copy
  pnpm add @terai/dev ai zod
  # Install your preferred AI SDK provider
  pnpm add @ai-sdk/openai  # For OpenAI
  # OR
  pnpm add @ai-sdk/anthropic  # For Anthropic
  # OR
  pnpm add @ai-sdk/groq  # For Groq
  ```
  </Tabs.Tab>
  <Tabs.Tab>
  ```bash copy
  yarn add @terai/dev ai zod
  # Install your preferred AI SDK provider
  yarn add @ai-sdk/openai  # For OpenAI
  # OR
  yarn add @ai-sdk/anthropic  # For Anthropic
  # OR
  yarn add @ai-sdk/groq  # For Groq
  ```
  </Tabs.Tab>
  <Tabs.Tab>
  ```bash copy
  bun add @terai/dev ai zod
  # Install your preferred AI SDK provider
  bun add @ai-sdk/openai  # For OpenAI
  # OR
  bun add @ai-sdk/anthropic  # For Anthropic
  # OR
  bun add @ai-sdk/groq  # For Groq
  ```
  </Tabs.Tab>
</Tabs>

### Configure Your Translator

Add the AI translator to your `terai.config.ts` file:

```ts filename="terai.config.ts" copy
import { defineConfig, createAiTranslator } from '@terai/dev'
import { createOpenAI } from '@ai-sdk/openai'

const openai = createOpenAI({
  apiKey: process.env.OPENAI_API_KEY
})

const translator = createAiTranslator({
  model: openai('gpt-4o')
})

export default defineConfig({
  include: ['./src/**/*.{js,jsx,ts,tsx}'],
  exclude: [],
  projectLocale: 'en-US',
  outLocales: ['es-ES', 'ja-JP', 'fr-FR'],
  outDir: './locale',
  translator
})
```

</Steps>

## Provider Examples

The AI translator works with any provider supported by the Vercel AI SDK. Here are examples for the most popular providers:

<Tabs items={['OpenAI', 'Anthropic', 'Groq', 'Google AI', 'Custom']}>
  <Tabs.Tab>
  ### OpenAI (ChatGPT)

  Best for: High-quality translations with excellent context understanding

  ```ts filename="terai.config.ts" {1-2,4-6,8-10}
  import { defineConfig, createAiTranslator } from '@terai/dev'
  import { createOpenAI } from '@ai-sdk/openai'

  const openai = createOpenAI({
    apiKey: process.env.OPENAI_API_KEY
  })

  const translator = createAiTranslator({
    model: openai('gpt-4o')  // or 'gpt-4o-mini', 'gpt-4-turbo'
  })

  export default defineConfig({
    projectLocale: 'en-US',
    outLocales: ['es-ES', 'ja-JP'],
    outDir: './locale',
    translator
  })
  ```

  **Recommended Models:**
  - `gpt-4o` - Best quality, supports structured outputs
  - `gpt-4o-mini` - Fast and cost-effective
  - `gpt-4-turbo` - Good balance of quality and speed

  </Tabs.Tab>
  <Tabs.Tab>
  ### Anthropic (Claude)

  Best for: Nuanced translations with strong reasoning capabilities

  ```ts filename="terai.config.ts" {1-2,4-6,8-10}
  import { defineConfig, createAiTranslator } from '@terai/dev'
  import { createAnthropic } from '@ai-sdk/anthropic'

  const anthropic = createAnthropic({
    apiKey: process.env.ANTHROPIC_API_KEY
  })

  const translator = createAiTranslator({
    model: anthropic('claude-3-5-sonnet-20241022')
  })

  export default defineConfig({
    projectLocale: 'en-US',
    outLocales: ['es-ES', 'ja-JP'],
    outDir: './locale',
    translator
  })
  ```

  **Recommended Models:**
  - `claude-3-5-sonnet-20241022` - Best quality and reasoning
  - `claude-3-5-haiku-20241022` - Fast and cost-effective
  - `claude-3-opus-20240229` - Highest quality (more expensive)

  </Tabs.Tab>
  <Tabs.Tab>
  ### Groq

  Best for: Ultra-fast translations with open-source models

  ```ts filename="terai.config.ts" {1-2,4-6,8-10}
  import { defineConfig, createAiTranslator } from '@terai/dev'
  import { createGroq } from '@ai-sdk/groq'

  const groq = createGroq({
    apiKey: process.env.GROQ_API_KEY
  })

  const translator = createAiTranslator({
    model: groq('llama-3.3-70b-versatile')
  })

  export default defineConfig({
    projectLocale: 'en-US',
    outLocales: ['es-ES', 'ja-JP'],
    outDir: './locale',
    translator
  })
  ```

  **Recommended Models:**
  - `llama-3.3-70b-versatile` - Excellent quality and speed
  - `llama-3.1-70b-versatile` - Good balance
  - `mixtral-8x7b-32768` - Large context window

  </Tabs.Tab>
  <Tabs.Tab>
  ### Google Generative AI

  Best for: Access to Gemini models

  ```ts filename="terai.config.ts" {1-2,4-6,8-10}
  import { defineConfig, createAiTranslator } from '@terai/dev'
  import { createGoogleGenerativeAI } from '@ai-sdk/google'

  const google = createGoogleGenerativeAI({
    apiKey: process.env.GOOGLE_GENERATIVE_AI_API_KEY
  })

  const translator = createAiTranslator({
    model: google('gemini-2.0-flash-exp')
  })

  export default defineConfig({
    projectLocale: 'en-US',
    outLocales: ['es-ES', 'ja-JP'],
    outDir: './locale',
    translator
  })
  ```

  **Recommended Models:**
  - `gemini-2.0-flash-exp` - Fast and efficient
  - `gemini-1.5-pro` - High quality
  - `gemini-1.5-flash` - Cost-effective

  </Tabs.Tab>
  <Tabs.Tab>
  ### Custom Provider

  You can use any provider that implements the `LanguageModelV1` interface:

  ```ts filename="terai.config.ts"
  import { defineConfig, createAiTranslator } from '@terai/dev'
  import { customProvider } from '@ai-sdk/custom-provider'

  const provider = customProvider({
    apiKey: process.env.CUSTOM_API_KEY,
    baseURL: 'https://api.example.com'
  })

  const translator = createAiTranslator({
    model: provider('model-name')
  })

  export default defineConfig({
    projectLocale: 'en-US',
    outLocales: ['es-ES', 'ja-JP'],
    outDir: './locale',
    translator
  })
  ```

  </Tabs.Tab>
</Tabs>

## Advanced Configuration

### Custom System Prompt

You can customize the translation behavior by providing your own system prompt:

```ts filename="terai.config.ts" {8-24}
import { defineConfig, createAiTranslator } from '@terai/dev'
import { createOpenAI } from '@ai-sdk/openai'

const openai = createOpenAI({
  apiKey: process.env.OPENAI_API_KEY
})

const customPrompt = `
You are a professional translator specializing in technical documentation.

## Translation Rules
- Maintain a formal, professional tone
- Use industry-standard terminology
- Preserve all code patterns and variables
- Keep translations concise for UI elements

## Critical Requirements
- Do NOT translate variable names like \${var} or {count}
- Do NOT translate HTML tags
- Return ONLY valid JSON with the same keys as input
`

const translator = createAiTranslator({
  model: openai('gpt-4o'),
  systemPrompt: customPrompt
})

export default defineConfig({
  projectLocale: 'en-US',
  outLocales: ['es-ES', 'ja-JP'],
  outDir: './locale',
  translator
})
```

### Output Mode Configuration

Control the structured output generation mode:

```ts filename="terai.config.ts" {8-11}
import { defineConfig, createAiTranslator } from '@terai/dev'
import { createOpenAI } from '@ai-sdk/openai'

const openai = createOpenAI({
  apiKey: process.env.OPENAI_API_KEY
})

const translator = createAiTranslator({
  model: openai('gpt-4o'),
  mode: 'json'  // 'json' (default) or 'auto'
})

export default defineConfig({
  projectLocale: 'en-US',
  outLocales: ['es-ES', 'ja-JP'],
  outDir: './locale',
  translator
})
```

- `json` (default): Uses JSON mode for structured output (requires compatible models)
- `auto`: Automatically determines the best mode based on model capabilities

## Environment Variables

For security, store your API keys in environment variables:

```bash filename=".env" copy
# OpenAI
OPENAI_API_KEY=sk-...

# Anthropic
ANTHROPIC_API_KEY=sk-ant-...

# Groq
GROQ_API_KEY=gsk_...

# Google
GOOGLE_GENERATIVE_AI_API_KEY=...
```

<Callout type="warning" emoji="⚠️">
  Never commit API keys to version control. Add `.env` to your `.gitignore` file.
</Callout>

## Translation Quality

The AI translator includes a sophisticated system prompt that ensures:

### Code Pattern Preservation

Template variables and code patterns are never translated:

```json
// Input (en-US)
{
  "welcome": "Welcome ${name}!",
  "items": "You have {count} items"
}

// Output (es-ES) ✅ Correct
{
  "welcome": "¡Bienvenido ${name}!",
  "items": "Tienes {count} elementos"
}

// ❌ Incorrect (variables would be preserved, not translated)
{
  "welcome": "¡Bienvenido Juan!",
  "items": "Tienes count elementos"
}
```

### HTML & Formatting Preservation

HTML tags and markdown are preserved:

```json
// Input (en-US)
{
  "link": "Click <strong>here</strong> to continue",
  "markdown": "Read the **documentation** for details"
}

// Output (es-ES)
{
  "link": "Haz clic <strong>aquí</strong> para continuar",
  "markdown": "Lee la **documentación** para más detalles"
}
```

### Context-Aware Translation

The translator understands different contexts:

- **UI Elements**: Keeps button/label text concise
- **Error Messages**: Maintains clear, actionable tone
- **Help Text**: Uses friendly, conversational language
- **Technical Terms**: Preserves industry-standard terminology

## Complete Example

Here's a complete example with best practices:

```ts filename="terai.config.ts" copy
import { defineConfig, createAiTranslator } from '@terai/dev'
import { createOpenAI } from '@ai-sdk/openai'
import dedent from 'dedent'

// Initialize AI provider
const openai = createOpenAI({
  apiKey: process.env.OPENAI_API_KEY
})

// Optional: Custom prompt for your specific use case
const customPrompt = dedent`
  # Expert Translator for E-commerce Platform

  You are translating an e-commerce application.
  Maintain a friendly, professional tone suitable for online shopping.

  ## Special Terminology
  - "Cart" should be translated as "Carrito" in Spanish
  - "Checkout" should be translated as "Pagar" in Spanish
  - Keep brand names untranslated

  ## Critical Requirements
  - Preserve template variables: \${var}, {count}, etc.
  - Maintain HTML tags and formatting
  - Return only valid JSON with identical keys
  - No newlines within string values
`

// Create translator
const translator = createAiTranslator({
  model: openai('gpt-4o'),
  systemPrompt: customPrompt,  // Optional
  mode: 'json'  // Optional, default is 'json'
})

// Export configuration
export default defineConfig({
  include: ['./src/**/*.{js,jsx,ts,tsx}'],
  exclude: ['./src/**/*.test.{js,jsx,ts,tsx}'],
  projectLocale: 'en-US',
  outLocales: ['es-ES', 'fr-FR', 'de-DE', 'ja-JP'],
  outDir: './locale',
  translator
})
```

## Usage Workflow

<Steps>

### Extract Messages

First, extract all translatable messages from your codebase:

```bash copy
pnpm terai extract
```

This creates your base dictionary in `locale/en-US/en-US.json`:

```json filename="locale/en-US/en-US.json"
{
  "abc123": "Hello, ${name}!",
  "def456": "You have {count} new messages",
  "ghi789": "Click <strong>here</strong> to continue"
}
```

### Translate Messages

Run the translation command to generate translations for all configured locales:

```bash copy
pnpm terai translate
```

The AI translator will create translated files:

```json filename="locale/es-ES/es-ES.json"
{
  "abc123": "¡Hola, ${name}!",
  "def456": "Tienes {count} mensajes nuevos",
  "ghi789": "Haz clic <strong>aquí</strong> para continuar"
}
```

```json filename="locale/ja-JP/ja-JP.json"
{
  "abc123": "こんにちは、${name}さん！",
  "def456": "{count}件の新しいメッセージがあります",
  "ghi789": "続けるには<strong>ここ</strong>をクリックしてください"
}
```

### Automatic Caching

Terai automatically caches translations to avoid re-translating identical strings, saving time and API costs.

</Steps>

## Best Practices

### 1. Choose the Right Model

- **Quality Priority**: Use `gpt-4o`, `claude-3-5-sonnet-20241022`, or `gemini-1.5-pro`
- **Speed Priority**: Use `gpt-4o-mini`, `claude-3-5-haiku-20241022`, or `llama-3.3-70b-versatile`
- **Cost Priority**: Use `gpt-4o-mini` or Groq models

### 2. Test Translations

Always review AI-generated translations, especially for:
- Critical UI elements (buttons, error messages)
- Legal or compliance-related text
- Brand-specific terminology

### 3. Use Environment Variables

Store API keys securely in environment variables, never in code:

```ts
// ✅ Good
const openai = createOpenAI({
  apiKey: process.env.OPENAI_API_KEY
})

// ❌ Bad
const openai = createOpenAI({
  apiKey: 'sk-...'  // Never hardcode!
})
```

### 4. Customize for Your Domain

If your app has specific terminology or tone requirements, provide a custom system prompt:

```ts
const translator = createAiTranslator({
  model: openai('gpt-4o'),
  systemPrompt: `
    Translation specialist for medical software.
    Use formal medical terminology.
    Maintain clinical accuracy.
    Preserve all medical codes and identifiers.
  `
})
```

### 5. Monitor API Costs

- Use cheaper models for development/testing
- Enable caching to avoid re-translating
- Consider using Groq for free/low-cost options during development

## Troubleshooting

### Translation Quality Issues

If translations are not meeting expectations:

1. **Use a more powerful model**: Switch to `gpt-4o` or `claude-3-5-sonnet-20241022`
2. **Customize the prompt**: Add domain-specific instructions
3. **Provide context**: Include terminology guidelines in your custom prompt

### API Rate Limits

If you hit rate limits:

1. **Use a different provider**: Groq offers high rate limits
2. **Batch translations**: Translate fewer locales at a time
3. **Increase tier**: Upgrade your API plan with the provider

### Variables Not Preserved

If template variables are being translated:

1. Ensure you're using the latest version of `@terai/dev`
2. Check that your model supports structured outputs
3. Verify the system prompt is not overriding variable preservation rules

## Migration from Old Translators

If you're migrating from the deprecated `createChatGptTranslator` or `createGoogleCloudTranslator`:

```diff filename="terai.config.ts"
- import { defineConfig, createChatGptTranslator } from '@terai/dev'
+ import { defineConfig, createAiTranslator } from '@terai/dev'
+ import { createOpenAI } from '@ai-sdk/openai'

+ const openai = createOpenAI({
+   apiKey: process.env.OPENAI_API_KEY
+ })

- const translator = createChatGptTranslator({
-   apiKey: process.env.OPENAI_API_KEY
- })
+ const translator = createAiTranslator({
+   model: openai('gpt-4o')
+ })

export default defineConfig({
  // ... rest of config
  translator
})
```

## API Reference

### `createAiTranslator(options)`

Creates an AI-powered translator function.

**Options:**

- `model` (required): AI model instance from any AI SDK provider
- `systemPrompt` (optional): Custom system prompt for translation behavior
- `mode` (optional): Output mode - `'json'` (default) or `'auto'`

**Returns:** `Translator` function compatible with Terai configuration

## Next Steps

- Learn about [Custom Translators](/docs/guides/custom-translator) for complete control
- Explore [Translation Concepts](/docs/concepts/translation) for deeper understanding
- Check [Configuration Reference](/docs/references/config) for all available options

## Resources

- [Vercel AI SDK Documentation](https://sdk.vercel.ai/)
- [Available AI SDK Providers](https://sdk.vercel.ai/providers)
- [Model Comparison Guide](https://sdk.vercel.ai/docs/ai-sdk-core/provider-comparison)
